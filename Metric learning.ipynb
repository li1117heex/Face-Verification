{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.image as imgplt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### our definition about LM3L classifier \n",
    "\n",
    "class LM3L_classifier:\n",
    "    def __init__(self, s_factor=1, rate=0.001, p=2, lamda=0.1, th=5, mg=1, T=10, err=0.001):\n",
    "        self.s_factor = s_factor\n",
    "        self.rate = rate\n",
    "        self.p = p\n",
    "        self.lamda = lamda\n",
    "        self.th = th\n",
    "        self.mg = mg\n",
    "        self.T = T\n",
    "        self.err = err\n",
    "    def training(self, samples, labels, K, epsilon = 1e-5):\n",
    "        ### step 1\n",
    "        ### Initialization(fin)\n",
    "        self.K = K\n",
    "        s_factor = self.s_factor\n",
    "        rate = self.rate\n",
    "        p = self.p\n",
    "        lamda = self.lamda\n",
    "        th = self.th\n",
    "        mg = self.mg\n",
    "        T = self.T\n",
    "        err = self.err\n",
    "        n = len(samples[0][0])\n",
    "        J0 = 0\n",
    "        J1 = 0\n",
    "        L = list()\n",
    "        I = np.zeros((K,1))/K\n",
    "        w = np.ones((K,1))/K\n",
    "        for k in range(K):\n",
    "            d = np.array(samples[k]).shape[0]\n",
    "            s = int(d/s_factor)\n",
    "            L.append(np.eye(s,d))\n",
    "\n",
    "\n",
    "        ### step 2\n",
    "        ### Alternating optimization\n",
    "        ## compute the initial loss function J0\n",
    "        # compute Ik\n",
    "        for k in range(K):\n",
    "            samplek = np.transpose(samples[k])\n",
    "            I[k] = 0\n",
    "            for i in range(int(n/2)):\n",
    "                vec = np.dot(L[k], np.transpose(samplek[2*i-1]-samplek[2*i-2]))\n",
    "                I[k] += hinge(mg-labels[i]*(th - np.linalg.norm(vec)**2))\n",
    "            print(\"I[%d] = %f\"%(k, I[k]))\n",
    "        # compute regulization term\n",
    "        R = 0\n",
    "        for i in range(int(n/2)):\n",
    "            for k in range(K):\n",
    "                samplek = np.transpose(samples[k])\n",
    "                for l in range(k):\n",
    "                    samplel = np.transpose(samples[l])\n",
    "                    vec1 = np.dot(L[k], np.transpose(samplek[2*i-1]-samplek[2*i-2]))\n",
    "                    vec2 = np.dot(L[l], np.transpose(samplel[2*i-1]-samplel[2*i-2]))\n",
    "                    dist =  (np.linalg.norm(vec1)- np.linalg.norm(vec2))**2\n",
    "                    R += dist\n",
    "        R = lamda*R\n",
    "        J0 = R\n",
    "        for k in range(K):\n",
    "            J0 += I[k]*w[k]**p\n",
    "        print(\"Initialized:\\n w = %s\\n J = %f\"%(w, J0))\n",
    "        # start optimization\n",
    "        for t in range(T):\n",
    "            for k in range(K):\n",
    "                samplek = np.transpose(np.array(samples[k]))\n",
    "                ## gradient descent for updating L\n",
    "                # compute the gradient use past L\n",
    "                d = np.array(samples[k]).shape[0]\n",
    "                C = np.zeros((d,d))\n",
    "                for i in range(int(n/2)):\n",
    "                    # we use adjustified sigmoid to approximate the derivation of hinge function\n",
    "                    veck = np.dot(L[k], np.transpose(samplek[2*i-1]-samplek[2*i-2]))\n",
    "                    distk = np.linalg.norm(veck)\n",
    "                    z = mg-labels[i]*(th - distk**2)\n",
    "                    coe = (w[k]**p)*labels[i]*sigmoid(z, 5)\n",
    "                    for l in range(K):  \n",
    "                        if l==k:\n",
    "                            continue\n",
    "                        samplel = np.transpose(samples[l])\n",
    "                        vecl = np.dot(L[l], np.transpose(samplel[2*i-1]-samplel[2*i-2]))\n",
    "                        distl = np.linalg.norm(vecl)\n",
    "                        coe += lamda*(1-np.sqrt(distl**2+epsilon)/np.sqrt(distk**2+epsilon))\n",
    "                    if i==0:\n",
    "                        C = coe*np.outer(samplek[2*i-1]-samplek[2*i-2],samplek[2*i-1]-samplek[2*i-2])\n",
    "                    else:\n",
    "                        C += coe*np.outer(samplek[2*i-1]-samplek[2*i-2],samplek[2*i-1]-samplek[2*i-2])\n",
    "                # compute new Lk ...\n",
    "                D = 2*np.dot(L[k], C)\n",
    "                L[k] = L[k]-rate*D\n",
    "                # ... and updated Ik using new Lk(fin)\n",
    "                I[k] = 0\n",
    "                for i in range(int(n/2)):\n",
    "                    vec = np.dot(L[k], np.transpose(samplek[2*i-1]-samplek[2*i-2]))\n",
    "                    I[k] += hinge(mg-labels[i]*(th - np.linalg.norm(vec)**2))\n",
    "            ## lagrange method for updating w using I[k]\n",
    "            w = (np.sqrt(I**2+epsilon))**(-1/(p-1))\n",
    "            w = w/sum(w) \n",
    "            ## compute new J, verify terminal condition(fin)\n",
    "            # compute new J1, just need to compute the regulization term(fin)\n",
    "            R = 0\n",
    "            for i in range(int(n/2)):\n",
    "                for k in range(K):\n",
    "                    samplek = np.transpose(samples[k])\n",
    "                    for l in range(k):\n",
    "                        samplel = np.transpose(samples[l])\n",
    "                        vec1 = np.dot(L[k], np.transpose(samplek[2*i-1]-samplek[2*i-2]))\n",
    "                        vec2 = np.dot(L[l], np.transpose(samplel[2*i-1]-samplel[2*i-2]))\n",
    "                        dist =  (np.linalg.norm(vec1)- np.linalg.norm(vec2))**2\n",
    "                        R += dist\n",
    "            R = lamda*R\n",
    "            J1 = R\n",
    "            for k in range(K):\n",
    "                J1 += I[k]*w[k]**p\n",
    "            print(J1)\n",
    "            # verify terminal condition(fin)\n",
    "            if abs(J1-J0) < err:\n",
    "                print(\"reach terminal condition\")\n",
    "                break;\n",
    "            else:\n",
    "                J0 = J1\n",
    "            times = t+1\n",
    "            print(\"Iteration %d times:\\n w = %s\\n J = %f\"%(times, w, J0))\n",
    "\n",
    "\n",
    "        ### step 3\n",
    "        ### Output distance metrics and weights(fin)\n",
    "        M = list()\n",
    "        for k in range(K):\n",
    "            M.append(np.dot(np.transpose(L[k]), L[k]))\n",
    "        self.L = L\n",
    "        self.M = M\n",
    "        self.w = w\n",
    "        print(\"algorithm terminated after %d times iteration\"%(times))\n",
    "        return (M, w)\n",
    "    def testing(self,samples):\n",
    "        th = self.th\n",
    "        w = self.w\n",
    "        L = self.L\n",
    "        p = self.p\n",
    "        K = self.K\n",
    "        result = list()\n",
    "        dists = list()\n",
    "        ### Initialization\n",
    "        n = np.shape(samples[0])[1]\n",
    "        th *= np.sum(w**p)\n",
    "        dist = 0\n",
    "        print(th)\n",
    "        for i in range(int(n/2)):\n",
    "            ### compute weighted distance\n",
    "            dist = 0\n",
    "            for k in range(K):\n",
    "                vec = np.dot(L[k],  np.transpose(samples[k][:,2*i-1]-samples[k][:,2*i-2]))\n",
    "                dist += (w[k]**p)*(np.linalg.norm(vec)**2)\n",
    "            #print(dist)\n",
    "            dists.append(dist)\n",
    "            if dist < th:\n",
    "                result.append(1)\n",
    "            else:\n",
    "                result.append(-1)\n",
    "        return dists, result\n",
    "        \n",
    "    def save(self, filename):\n",
    "        print(\"gaoshi\")\n",
    "    \n",
    "def split_features(features, train_number):\n",
    "    train=[[] for i in features]\n",
    "    test=[[] for i in features]\n",
    "    randnum=random.sample(range(1600),train_number)\n",
    "    for i in range(1600):\n",
    "        if i in randnum:\n",
    "            for j in range(len(features)):\n",
    "                train[j].extend([features[j][2*i],features[j][2*i+1]])\n",
    "        else:\n",
    "            for j in range(len(features)):\n",
    "                test[j].extend([features[j][2*i],features[j][2*i+1]])\n",
    "    randnum=random.sample(range(1600),train_number)\n",
    "    for i in range(1600):\n",
    "        if i in randnum:\n",
    "            for j in range(len(features)):\n",
    "                train[j].extend([features[j][3200+2*i],features[j][3200+2*i+1]])\n",
    "        else:\n",
    "            for j in range(len(features)):\n",
    "                test[j].extend([features[j][3200+2*i],features[j][3200+2*i+1]])\n",
    "    print(\"finish\")\n",
    "    train_label = np.concatenate([np.ones(train_number),np.zeros(train_number)-1],axis=0)\n",
    "    test_label = np.concatenate([np.ones(1600-train_number),np.zeros(1600-train_number)-1],axis=0)\n",
    "    return train,test,train_label,test_label\n",
    "    \n",
    "    \n",
    "def evaluate(result:np.ndarray,label:np.ndarray):\n",
    "    result1=result==1\n",
    "    label1=label==1\n",
    "    tp=(result[result1]==label[result1]).sum()\n",
    "    fp=result1.sum()-tp\n",
    "    tn=(result[~result1]==label[~result1]).sum()\n",
    "    fn=label1.sum()-tp\n",
    "    print(tp,fp,tn,fn)\n",
    "    accuracy = (tp+tn)/result.shape[0]\n",
    "    presicion = tp/(tp+fp)\n",
    "    recall = tp/(tp+fn)\n",
    "    f1 = 2/(1/presicion+1/recall)\n",
    "    print(f\"accuracy:{accuracy}\\npresicion:{presicion}\\nrecall:{recall}\\nf1 score:{f1}\")\n",
    "    return accuracy,presicion,recall,f1\n",
    "\n",
    "def hinge(x):\n",
    "    if x >= 0:\n",
    "        return x\n",
    "    return 0\n",
    "\n",
    "def sigmoid(x, a):\n",
    "    y = np.exp(-a*x)\n",
    "    y = 1/(1+y)\n",
    "    return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### some functions about input, output and feature extraction\n",
    "\n",
    "def get_all_path(dirpath, *suffix):\n",
    "    PathArray = []\n",
    "    for r, ds, fs in os.walk(dirpath):\n",
    "        for fn in fs:\n",
    "            if os.path.splitext(fn)[1] in suffix:\n",
    "                fname = os.path.join(r, fn)\n",
    "                PathArray.append(fname)\n",
    "    return PathArray\n",
    "\n",
    "sourcePath = r'C:\\Users\\Yunfeiman\\Desktop\\courses\\19q\\Project\\LFW'\n",
    "\n",
    "\n",
    "def get_imgs(dirpath):\n",
    "    ### initialization\n",
    "    images = list()\n",
    "    ### ge all pictures into arrays\n",
    "    ## get paths\n",
    "    imagepaths = get_all_path(dirpath, '.jpg')\n",
    "    ## translate into gray\n",
    "    for path in imagepaths:\n",
    "        img = cv2.imread(path)\n",
    "        img = img[50:200,85:165]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "def get_lbp_pattern(block,block_size):\n",
    "    pattern = np.zeros(8)\n",
    "    feature = []\n",
    "    for i in range(1, block_size[0] - 1):\n",
    "        for j in range(1, block_size[1] - 1):\n",
    "            pattern[0] = block[i - 1, j - 1] > block[i, j]\n",
    "            pattern[1] = block[i - 1, j] > block[i, j]\n",
    "            pattern[2] = block[i - 1, j + 1] > block[i, j]\n",
    "            pattern[3] = block[i, j + 1] > block[i, j]\n",
    "            pattern[4] = block[i + 1, j + 1] > block[i, j]\n",
    "            pattern[5] = block[i + 1, j ] > block[i, j]\n",
    "            pattern[6] = block[i + 1, j - 1] > block[i, j]\n",
    "            pattern[7] = block[i, j - 1] > block[i, j]\n",
    "            diff = np.array([pattern[i-1]!=pattern[i] for i in range(8)]).sum()\n",
    "            if diff<=2:\n",
    "                feature.append(np.dot(pattern,[2**i for i in range(8)]))\n",
    "            else:\n",
    "                feature.append(-1)\n",
    "    return np.array(feature)\n",
    "\n",
    "def lbp(input:np.ndarray,block_size=(15,16)):#int8 input with dim=2,edge around blocks is ignored\n",
    "    uniform=[0, 1, 2, 3, 4, 6, 7, 8, 12, 14, 15, 16, 24, 28, 30, 31, 32, 48, 56, 60, 62, 63, 64, 96, 112, 120, 124, 126, 127, 128, 129, 131, 135, 143, 159, 191, 192, 193, 195, 199, 207, 223, 224, 225, 227, 231, 239, 240, 241, 243, 247, 248, 249, 251, 252, 253, 254, 255]\n",
    "    if input.ndim!=2:\n",
    "        print(\"input dim!=2\")\n",
    "    else:\n",
    "        row_index = 0\n",
    "        feature = []\n",
    "        block_feature = []\n",
    "        while row_index+block_size[0]<=input.shape[0]:\n",
    "            column_index = 0\n",
    "            while column_index+block_size[1]<=input.shape[1]:\n",
    "                block_feature = []\n",
    "                block = input[row_index:row_index+block_size[0],column_index:column_index+block_size[1]]\n",
    "                pattern = get_lbp_pattern(block,block_size)\n",
    "                block_feature.append(np.sum(pattern==-1))\n",
    "                block_feature.extend([np.sum(pattern==i) for i in uniform])\n",
    "                block_feature=np.array(block_feature)\n",
    "                feature.append(block_feature/block_feature.sum())\n",
    "                column_index+=block_size[1]\n",
    "            row_index += block_size[0]\n",
    "        return np.concatenate(feature,axis=0)\n",
    "    \n",
    "\n",
    "def extract_lbp(images):\n",
    "    lbp_features = list()\n",
    "    for image in images:\n",
    "        lbp_features.append(lbp(np.array(image)))\n",
    "    return lbp_features\n",
    "\n",
    "def get_hog_pattern(cell,cellSize = (8,8)):\n",
    "    gx = np.zeros((cellSize[0]-2,cellSize[1]-2))\n",
    "    gy = np.zeros((cellSize[0]-2,cellSize[1]-2))\n",
    "    for i in range(1, cellSize[0] - 1):\n",
    "        for j in range(1, cellSize[1] - 1):\n",
    "            gx[i-1,j-1] = float(cell[i,j+1])-float(cell[i,j-1])\n",
    "            gy[i-1,j-1] = float(cell[i+1,j])-float(cell[i-1,j])\n",
    "\n",
    "    gra_mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    gra_dir = np.arctan2(gy,gx)/np.pi\n",
    "    return gra_dir.flatten(),gra_mag.flatten()\n",
    "\n",
    "def hog(input:np.ndarray,blockSize = (2,2),blockStride = (1,1),cellSize = (8,8),nbins = 9):\n",
    "    if input.ndim!=2:\n",
    "        print(\"input dim!=2\")\n",
    "    else:\n",
    "        cell_feature = np.zeros((int(input.shape[0]/cellSize[0]),int(input.shape[1]/cellSize[1]),9))\n",
    "        row_index = 0\n",
    "        row=0\n",
    "        while row_index + cellSize[0] <= input.shape[0]:\n",
    "            column_index = 0\n",
    "            column=0\n",
    "            while column_index+cellSize[1] <=input.shape[1]:\n",
    "                one_cell_feature = np.zeros(11)\n",
    "                cell = input[row_index:row_index + cellSize[0], column_index:column_index + cellSize[1]]\n",
    "                gradient_dir,gradient_mag =get_hog_pattern(cell,cellSize)\n",
    "                gradient_dir = gradient_dir*nbins\n",
    "                for i in range(gradient_dir.shape[0]):\n",
    "                    low = int(np.floor(gradient_dir[i]))\n",
    "                    high = low+1\n",
    "                    one_cell_feature[low]+=(high-gradient_dir[i])*gradient_mag[i]\n",
    "                    one_cell_feature[high]+=(gradient_dir[i]-low)*gradient_mag[i]\n",
    "                one_cell_feature[0]+=one_cell_feature[9]\n",
    "                cell_feature[row,column] = one_cell_feature[:9]\n",
    "                column_index+=cellSize[1]\n",
    "                column+=1\n",
    "            row_index+=cellSize[0]\n",
    "            row+=1\n",
    "        print((cell_feature<0).sum())\n",
    "        row_index = 0\n",
    "        block_feature = []\n",
    "        while row_index + blockSize[0] <= cell_feature.shape[0]:\n",
    "            column_index = 0\n",
    "            while column_index+blockSize[1] <=cell_feature.shape[1]:\n",
    "                one_block_feature=cell_feature[row_index:row_index+blockSize[0],column_index:column_index+blockSize[1]].flatten()\n",
    "                block_feature.append(one_block_feature/(np.linalg.norm(one_block_feature)))\n",
    "                column_index+=blockStride[1]\n",
    "            row_index+=blockStride[0]\n",
    "        return np.concatenate(block_feature, axis=0)\n",
    "    \n",
    "def extract_hog(images):\n",
    "    hog_features = list()\n",
    "    for image in images:\n",
    "        hog_features.append(hog(np.array(image)))\n",
    "    return np.concatenate(hog_features,axis=1)\n",
    "\n",
    "def get_cslbp_pattern(block,block_size,threshold):\n",
    "    pattern = np.zeros(4)\n",
    "    feature = []\n",
    "    for i in range(1, block_size[0] - 1):\n",
    "        for j in range(1, block_size[1] - 1):\n",
    "            pattern[0] = block[i - 1, j - 1] > block[i + 1, j + 1]+threshold\n",
    "            pattern[1] = block[i - 1, j] > block[i + 1, j ]+threshold\n",
    "            pattern[2] = block[i - 1, j + 1] > block[i + 1, j - 1]+threshold\n",
    "            pattern[3] = block[i, j + 1] > block[i, j - 1]+threshold\n",
    "            feature.append(np.dot(pattern,[2**i for i in range(4)]))\n",
    "    return np.array(feature)\n",
    "\n",
    "def cslbp(input:np.ndarray,block_size=(10,10),threshold=0):\n",
    "    if input.ndim!=2:\n",
    "        print(\"input dim!=2\")\n",
    "    else:\n",
    "        row_index = 0\n",
    "        feature = []\n",
    "        while row_index + block_size[0] <= input.shape[0]:\n",
    "            column_index = 0\n",
    "            while column_index + block_size[1] <= input.shape[1]:\n",
    "                block = input[row_index:row_index + block_size[0], column_index:column_index + block_size[1]]\n",
    "                pattern = get_cslbp_pattern(block, block_size,threshold)\n",
    "                block_feature = np.array([np.sum(pattern == i) for i in range(16)])\n",
    "                feature.append(block_feature / block_feature.sum())\n",
    "                column_index += block_size[1]\n",
    "            row_index += block_size[0]\n",
    "        return np.concatenate(feature, axis=0)\n",
    "\n",
    "def extract_cslbp(images):\n",
    "    cslbp_features = list()\n",
    "    for image in images:\n",
    "        cslbp_features.append(cslbp(np.array(image)))\n",
    "    return cslbp_features\n",
    "    \n",
    "def WPCA(features, dimension=200, epsilon=1e-5):\n",
    "    ### compute cov matrix\n",
    "    print(\"start computing cov matrix\")\n",
    "    mean = np.mean(features, axis=0)\n",
    "    features-= mean\n",
    "    cov = np.dot(np.transpose(features), features)\n",
    "    print(np.linalg.matrix_rank(cov))\n",
    "    print(np.shape(cov))\n",
    "    print(\"start eigen-decomposition\")\n",
    "    ### eigen-decomposition\n",
    "    evalue, evector = np.linalg.eig(cov)\n",
    "    print(evalue)\n",
    "    ### return the reduce matrix and reduced features\n",
    "    revector = evector[:,:dimension]\n",
    "    reduced_feature = np.dot(features, revector)\n",
    "    print(\"start whiten\")\n",
    "    ### whiten\n",
    "    n = len(features)\n",
    "    stds = list()\n",
    "    for i in range(dimension):\n",
    "        std = np.linalg.norm(reduced_feature[:,i])\n",
    "        stds.append(std)\n",
    "        reduced_feature[:,i] = reduced_feature[:,i]/np.sqrt(std**2+epsilon)\n",
    "    return revector, reduced_feature, mean, stds\n",
    "\n",
    "def test_WPCA(features, revector, mean, stds, epsilon=1e-5, dimension=200):\n",
    "    features -= mean\n",
    "    reduced_feature = np.dot(features, revector)\n",
    "    for i in range(dimension):\n",
    "        reduced_feature[:, i] /= np.sqrt(stds[i]**2+epsilon)\n",
    "    return reduced_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list()\n",
    "for i in range(1600):\n",
    "    labels.append(1)\n",
    "for i in range(1600):\n",
    "    labels.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = get_imgs(sourcePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flbp = extract_lbp(images)\n",
    "fcslbp = extract_cslbp(images)\n",
    "fhog = extract_hog(images)\n",
    "fhog = np.transpose(fhog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, train_label, test_label = split_features([flbp, fhog, fcslbp], 1280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_matrix_flbp, reduced_flbp, mean_flbp, stds_flbp = WPCA(train[0])\n",
    "reduce_matrix_fhog, reduced_fhog, mean_fhog, stds_fhog = WPCA(train[1])\n",
    "reduce_matrix_fcslbp, reduced_fcslbp, mean_fcslbp, stds_fcslbp = WPCA(train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train\n",
    "feature_hog = np.transpose(reduced_fhog)\n",
    "feature_lbp = np.transpose(reduced_flbp)\n",
    "feature_cslbp = np.transpose(reduced_fcslbp)\n",
    "features = [feature_lbp,feature_hog, feature_cslbp]\n",
    "LM3L = LM3L_classifier(rate=2, T=300)\n",
    "M, w = LM3L.training(features, train_label, len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test\n",
    "test[0] = test_WPCA(test[0], reduce_matrix_flbp, mean_flbp, stds_flbp)\n",
    "test[1] = test_WPCA(test[1], reduce_matrix_fhog, mean_fhog, stds_fhog)\n",
    "test[2] = test_WPCA(test[2], reduce_matrix_fcslbp, mean_fcslbp, stds_fcslbp)\n",
    "tf_lbp = np.transpose(test[0])\n",
    "tf_hog = np.transpose(test[1])\n",
    "tf_cslbp = np.transpose(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feature = [tf_lbp, tf_hog, tf_cslbp]\n",
    "dists, result = LM3L.testing(test_feature)\n",
    "evaluate(np.array(result),np.array(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for comming test\n",
    "test_source_path = \"\"\n",
    "test_images = get_imgs(sourcePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flbp = extract_lbp(test_images)\n",
    "test_fhog = extract_hog(test_images)\n",
    "test_fhog = np.transpose(test_fhog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flbp = np.transpose(test_WPCA(test_flbp, reduce_matrix_flbp, mean_flbp, stds_flbp))\n",
    "test_fhog = np.transpose(test_WPCA(test_fhog, reduce_matrix_fhog, mean_fhog, stds_fhog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists, result = LM3L.testing(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results.txt\", 'w')\n",
    "for i in range(len(result)):\n",
    "    if(result[i]==1):\n",
    "        f.write('1\\n')\n",
    "    else:\n",
    "        f.write('0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
